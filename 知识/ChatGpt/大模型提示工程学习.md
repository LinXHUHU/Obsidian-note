

# 任务描述和输入数据

Jinhao Jiang et al. “StructGPT: A General Framework for Large Language Model to Reason
over Structured Data”. In: arXiv preprint arXiv:2305.09645 (2023).
例如，对于结构化数据（如知识图谱、表格等），通常使用线性化方法将其转
换为易于处理的文本序列[264]。

![[Pasted image 20240517135958.png]]


# 上下文信息

![[Pasted image 20240517140331.png]]

# 提示策略

使用前缀“让我们一步一步地思考”可以激发大语
言模型的逐步推理能力

使用前缀“你是这项任务（或这个领域）的专家”可以
提高大语言模型在某些特定任务（或领域）中的表现

ChatGPT），由于其使用了大量对话数据进行训练，因此更合适的做
法是将提示拆分为多个子任务提示，以多轮对话的方法逐步输入给大语言模型。



# 设计

• 清晰地表达任务目标.
应当包含任务的各种要素信息，如任务目标、输入/输出
数据（


分解为简单且详细的子任务. 该原则的目标是将一个复杂任务分解为若干个
相对独立但又相互关联的子任务，每个子任务都对应原始任务的某个方面或步骤。
特别地，我们可以显式地将子任务按编号列出（例如，“通过依次执行以下任务形
成一段连贯的叙述：1. ...; 2. ...; 3. ...”）。这种策略有助于减少复杂任务的解决难
度：通过将复杂任务分解为若干个子任务并按照一定的顺序处理这些子任务，模
型能够逐步获得最终的答案。



• 提供少样本示例. 正如第10.2 节所介绍的上下文学习方法，在提示中加入少
量目标任务的输入输出作为任务示例（即少样本示例），可以提升大语言模型解决
复杂任务的能力。少样本示例有助于大语言模型在无需调整参数的前提下学习输
入与输出之间的语义映射关系。在实践中，我们可以根据目标任务专门为大语言
模型设计若干高质量的示例



• 采用模型友好的提示格式. 大语言模型采用专门构建的数据集进行预训练，
因此可以从数据集中学习到大量的语言表达模式，发现并利用这些语言表达模
式可以帮助我们更有效地使用大语言模型完成特定任务。对于提示中需要重点
强调的部分，OpenAI 官方文档中建议用户可以使用特殊符号（例如♯♯♯、三引号
“““和”””、XML 标签等）进行分隔，从而让大语言模型更好地理解相关内容。此
外，大多数现有的大语言模型主要在英语文本上进行训练，理解英语指令的能力
更强，因此在执行任务时使用英语指令可能会获得更好的执行效果。对于非英语
用户来说，通过机器翻译工具将非英语任务指令转换为英语指令再输入给大语言
模型，可能会是一个更有效的策略。（ 分隔符，xml  英文输入）



